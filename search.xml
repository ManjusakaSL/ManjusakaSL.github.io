<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Linux用户空间与内核空间</title>
      <link href="/Linux%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%E4%B8%8E%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4.html"/>
      <url>/Linux%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%E4%B8%8E%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4.html</url>
      
        <content type="html"><![CDATA[<h1 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h1><p>考虑32位的Linux操作系统，最高的 1G 字节(从虚拟地址 0xC0000000 到 0xFFFFFFFF)由内核使用，称为内核空间。而较低的 3G 字节(从虚拟地址 0x00000000 到 0xBFFFFFFF)由各个进程使用，称为用户空间。 也就是说：<strong>每个进程的 4G 地址空间中，最高 1G 是内核空间，所有进程共享，剩余的 3G 才归进程自己使用</strong>。</p><p><img src="/%E5%86%85%E5%AD%98%E5%88%86%E5%B8%83.png" alt="内存分布"></p><p>内核空间中存放的是内核代码和数据，而进程的用户空间中存放的是用户程序的代码和数据。</p><p><strong>问题：为什么需要区分内核空间和用户空间？</strong></p><p>在 CPU 的所有指令中，有些指令是非常危险的，如果错用，将导致系统崩溃，比如清内存、设置时钟等。如果允许所有的程序都可以使用这些指令，那么系统崩溃的概率将大大增加。</p><p>所以，CPU 将指令分为<strong>特权指令</strong>和<strong>非特权指令</strong>，对于那些危险的指令，只允许操作系统及其相关模块使用，普通应用程序只能使用那些不会造成灾难的指令。比如 Intel 的 CPU 将特权等级分为 4 个级别：Ring0~Ring3。 其实 Linux 系统只使用了 Ring0 和 Ring3 两个运行级别(Windows 系统也是一样的)。当进程运行在 Ring3 级别时被称为运行在用户态，而运行在 Ring0 级别时被称为运行在内核态。</p><p><strong>当进程运行在内核空间时就处于内核态，而进程运行在用户空间时则处于用户态。</strong></p><ul><li>在内核态下，进程运行在内核地址空间中，此时 CPU  可以执行任何指令。运行的代码也不受任何的限制，可以自由地访问任何有效地址，也可以直接进行端口的访问。 </li><li>在用户态下，进程运行在用户地址空间中，被执行的代码要受到 CPU     的诸多检查。</li></ul><p>举个例子：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">str = <span class="string">&quot;my string&quot;</span> <span class="comment">// 用户态</span></span><br><span class="line">x = x + <span class="number">2</span>         <span class="comment">// 用户态</span></span><br><span class="line">file.<span class="built_in">write</span>(str)   <span class="comment">// 切换到内核态</span></span><br><span class="line">y = x + <span class="number">4</span>         <span class="comment">// 切换回用户态</span></span><br></pre></td></tr></table></figure><h1 id="二、用户态和内核态的切换方式"><a href="#二、用户态和内核态的切换方式" class="headerlink" title="二、用户态和内核态的切换方式"></a>二、用户态和内核态的切换方式</h1><p>三种方式：<strong>系统调用、软中断和硬件中断</strong>。</p><p><img src="/%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E7%9A%84%E5%88%87%E6%8D%A2%E6%96%B9%E5%BC%8F.png" alt="2"></p><p>将每个处理器在任何指定时间点上的活动概括为下列三者之一：</p><ul><li>运行于用户空间，执行用户进程。</li><li>运行于内核空间，处于进程上下文，代表某个特定的进程执行。</li><li>运行于内核空间，处于中断上下文，与任何进程无关，处理某个特定的中断。</li></ul><h1 id="三、用户空间和内核空间的数据交互"><a href="#三、用户空间和内核空间的数据交互" class="headerlink" title="三、用户空间和内核空间的数据交互"></a>三、用户空间和内核空间的数据交互</h1><p>如果应用程序传入了一个参数user_arg，指向的是用户空间的地址。那么我们在内核态里能否直接从这个地址读取数据呢？</p><p>答案是肯定的，因为内核能够看到进程的整个地址空间，属于这个进程的所有page在此进程的page table里，内核函数当然可以访问那个指针user_arg。那么为什么一定要用<strong>copy_from_user&#x2F;copy_to_user</strong>，而不是直接用memcpy或者直接dereference那个地址？</p><p>以write函数举例好了：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">write</span>(<span class="keyword">struct</span> file *filp, <span class="type">const</span> <span class="type">char</span> __user *buf, <span class="type">size_t</span> len, <span class="type">loff_t</span> *ppos);</span><br></pre></td></tr></table></figure><p>关于参数buf有三种情况：</p><ol><li>buf地址不合法；</li><li>buf地址合法，考虑的MMU的特性，内核可能没有给它分配物理地址（并不是合法的虚拟地址都会对应到物理地址，可能它实际会被存储到磁盘上，通过缺页异常来获取其内容）</li><li>buf地址被精心伪造成内核地址，导致出现安全性问题；</li></ol><p>为了解决这个问题，就出现了copy_from_user函数：</p><ul><li>buf地址不合法：地址检查，不合法返回。</li><li>buf地址合法但是没有分配物理地址：copy_from_user函数引发缺页异常，并进行处理。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Linux嵌入式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Android相机架构</title>
      <link href="/Android%E7%9B%B8%E6%9C%BA%E6%9E%B6%E6%9E%84.html"/>
      <url>/Android%E7%9B%B8%E6%9C%BA%E6%9E%B6%E6%9E%84.html</url>
      
        <content type="html"><![CDATA[<h1 id="Architecture-Legacy"><a href="#Architecture-Legacy" class="headerlink" title="Architecture Legacy"></a>Architecture Legacy</h1><p><img src="/Android%E7%9B%B8%E6%9C%BA%E6%9E%B6%E6%9E%84/ape_fwk_camera.png" alt="Android 相机架构"><br>Android Camera当前提供了两套API：API1.0和API2.0。API1.0和API2.0的区别是：</p><p>(1) API1.0相对简单且易于使用，应用可以做的事情不多。<br>(2) API2.0则要复杂得多，但是应用程序可以对底层相机有更多的控制权。比如：efficient zero-copy burst&#x2F;streaming flows and per-frame controls of exposure, gain, white balance gains, color conversion, denoising, sharpening, and more.<br>由于Android软件每次更新总是会做到向前兼容，所以在现在的版本上API1.0的相机也是可以跑起来的。但是当前API1.0 Google已经不再提供更新，它会逐渐被淘汰掉。<br>有关更多Android各版本的细节参考：<a href="https://source.android.google.cn/devices/camera/versioning">https://source.android.google.cn/devices/camera/versioning</a></p><h1 id="整体架构概述（Camera2-HAL3）"><a href="#整体架构概述（Camera2-HAL3）" class="headerlink" title="整体架构概述（Camera2 + HAL3）"></a>整体架构概述（Camera2 + HAL3）</h1><p>Android Camera整体框架主要包括三个进程：<strong>app进程、camera server进程、hal进程（provider进程）</strong>。进程之间的通信都是通过binder实现，其中app和camera server通信使用 <a href="https://developer.android.com/guide/components/aidl">AIDL(Android Interface Definition Language)</a> ，camera server和hal（provider进程）通信使用<a href="https://source.android.com/devices/architecture/hidl">HIDL(HAL interface definition language)</a> 。<br>Android Camera2整体架构如下图：</p><p><img src="/Android%E7%9B%B8%E6%9C%BA%E6%9E%B6%E6%9E%84/ape_fwk_camera2.png" alt="Android 相机架构"><br>上图Kernel层没有画出来，其它基本可以和Android系统框架对应起来。<br>大致分为这几个部分：</p><ol><li><p><strong>Application framework</strong><br>这一层是用于给APP提供访问hardware的Camera API2，通过binder来访问camera service。有两个主要的类：</p><blockquote><p>(1) CameraManager，CameraManager是一个独一无二地用于检测、连接和描述相机设备的系统服务,负责管理所有的CameraDevice相机设备。通过ICameraService调用到CameraService。</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// CameraManager.java</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">connectCameraServiceLocked</span><span class="params">()</span> &#123;  <span class="comment">// CameraManager是一个系统服务，应该是开机就会被创建起来</span></span><br><span class="line"><span class="type">IBinder</span> <span class="variable">cameraServiceBinder</span> <span class="operator">=</span> ServiceManager.getService(CAMERA_SERVICE_BINDER_NAME);</span><br><span class="line"><span class="type">ICameraService</span> <span class="variable">cameraService</span> <span class="operator">=</span> ICameraService.Stub.asInterface(cameraServiceBinder);  <span class="comment">// 返回Stub.Proxy对象，也就是ICameraServiceProxy</span></span><br><span class="line">CameraStatus[] cameraStatuses = cameraService.addListener(<span class="built_in">this</span>);                      <span class="comment">// 注册 ICameraServiceListener                </span></span><br><span class="line">mCameraService = cameraService;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>(2) CameraDevice：CameraDevice是连接在安卓设备上的单个相机的抽象表示。通过ICameraDeviceUser调用到CameraDeviceClient。<br>CameraDevice是抽象类，CameraDeviceImpl.java继承了CameraDevice.java，并完成了抽象方法的具体实现。</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> CameraDevice <span class="title function_">openCameraDeviceUserAsync</span><span class="params">()</span> &#123;</span><br><span class="line"><span class="type">CameraDevice</span> <span class="variable">device</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"><span class="type">ICameraDeviceUser</span> <span class="variable">cameraUser</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">android.hardware.camera2.impl.<span class="type">CameraDeviceImpl</span> <span class="variable">deviceImpl</span> <span class="operator">=</span>      <span class="comment">// CameraDeviceImp继承自CameraDevice</span></span><br><span class="line"><span class="keyword">new</span> <span class="title class_">android</span>.hardware.camera2.impl.CameraDeviceImpl(cameraId, ...);</span><br><span class="line"><span class="type">ICameraDeviceCallbacks</span> <span class="variable">callbacks</span> <span class="operator">=</span> deviceImpl.getCallbacks();    <span class="comment">// 获取CameraDevice的回调函数</span></span><br><span class="line"><span class="type">ICameraService</span> <span class="variable">cameraService</span> <span class="operator">=</span> CameraManagerGlobal.get().getCameraService();</span><br><span class="line">cameraUser = cameraService.connectDevice(callbacks, cameraId, ...);  <span class="comment">// connect到camera service，并将camera device callback注册进去</span></span><br><span class="line">deviceImpl.setRemoteDevice(cameraUser);<span class="comment">// 返回的ICameraDeviceUser就是CameraDeviceClient的本地接口</span></span><br><span class="line">device = deviceImpl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> device;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>Native framework</strong><br>代码路径位于：frameworks&#x2F;av&#x2F;camera&#x2F;。提供了ICameraService、ICameraDeviceUser、ICameraDeviceCallbacks、ICameraServiceListener等aidl接口的实现。以及camera server的main函数。<br>AIDL基于Binder实现的一个用于让App fw代码访问native fw代码的接口。其实现存在于下述路径：frameworks&#x2F;av&#x2F;camera&#x2F;aidl&#x2F;android&#x2F;hardware。</p><blockquote><p>(1) ICameraService 是相机服务的接口。用于请求连接、添加监听等。<br>(2) ICameraDeviceUser 是已打开的特定相机设备的接口。应用框架可通过它访问具体设备。<br>(3) ICameraServiceListener 和 ICameraDeviceCallbacks 分别是从 CameraService 和 CameraDevice 到应用框架的回调。</p></blockquote></li><li><p><strong>Camera Service</strong><br>代码路径：frameworks&#x2F;av&#x2F;services&#x2F;camera&#x2F;。向上向APP提供服务，向下从HAL获取数据。</p><blockquote><p>(1) CameraService：如其名，相机服务，手机启动时会生成该类的对象。应用对ICameraService的函数调用，会访问到CameraService。<br>(2) CameraDeviceClient：当应用调用 openCamera() 打开指定相机设备时，会生成一个对应的CameraDeviceClient。应用通过对ICameraDeviceUser的函数调用，会访问到CameraDeviceClient。<br>(3) CameraProviderManager：CameraService对象生成时，创建的对象。同HAL交互。<br>(4) Camera3Device：应用调用 openCamera() 时生成该类的对象，即具体的Camera设备。</p></blockquote><p> 作为系统工程师，Camera3Device的逻辑重点搞明白，这里是相当于是HAL的控制逻辑起始处，下图是Camera3Device和CameraProviderManager的UML类图：<br> <img src="/Android%E7%9B%B8%E6%9C%BA%E6%9E%B6%E6%9E%84/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM5NjE3MTg=,size_16,color_FFFFFF,t_70.png" alt="img"></p></li><li><p><strong>HAL</strong><br> Google的HAL定义了可以让Camera Service访问的标准接口。有关这些接口的具体实现则交由硬件厂商。</p><p> 代码路径：&#x2F;hardware&#x2F;interfaces&#x2F;camera，下面是从该目录的 README.md 里面的内容。</p><blockquote><p>The camera.* HAL tree is used by the Android camera service to discover and operate camera devices available on the device.<br> More details and versioning information can be found within each particular HAL.<br>More complete information about the Android camera HAL and subsystem can be found at <a href="http://source.android.com/devices/camera/index.html">source.android.com</a>.</p></blockquote></li></ol><h1 id="核心概念：Request"><a href="#核心概念：Request" class="headerlink" title="核心概念：Request"></a>核心概念：Request</h1><p>request是贯穿camera2数据处理流程最为重要的概念，<strong>应用框架是通过向camera子系统发送request来获取其想要的result</strong>。request有下述几个重要特征：</p><ol><li>一个request可以对应一系列的result。</li><li>request应当包含所有必要的配置信息，存放于metadata中。如：分辨率和像素格式；sensor、镜头、闪光等的控制信息；3A 操作模式；RAW 到 YUV 处理控件；以及统计信息的生成等。</li><li>request需要携带对应的surface（也就是框架里面的stream），用于接收返回的图像。</li><li>多个request可以同时处于in-flight状态，并且submit request是non-blocking方式的。也就是说，上一个request没有处理完，也可以submit新的request。</li><li>队列中request的处理总是按照FIFO的形式。</li><li>snapshot的request的preview的request拥有更高的优先级。</li></ol><p>request的整体处理流程如下图：<br><img src="/Android%E7%9B%B8%E6%9C%BA%E6%9E%B6%E6%9E%84/camera_model.png" alt="相机请求模型"></p><ul><li>open 流程（黑色箭头线条）<ul><li>CameraManager注册AvailabilityCallback回调，用于接收相机设备的可用性状态变更的通知。</li><li>CameraManager通过调用getCameraIdList()获取到当前可用的camera id，通过getCameraCharacteristcs()函数获取到指定相机设备的特性。</li><li>CameraManager调用openCamera()打开指定相机设备，并返回一个CameraDevice对象，后续通过该CameraDevice对象操控具体的相机设备。</li><li>使用CameraDevice对象的createCaptureSession()创建一个session，数据请求（预览、拍照等）都是通过session进行。在创建session时，需要提供Surface作为参数，用于接收返回的图像。</li></ul></li><li>configure stream流程（蓝色箭头线条）<ul><li>申请Surface，如上图的OUTPUT STREAMS DESTINATIONS框，用于在创建session时作为参数，接收session返回的图像。</li><li>创建session后，surface会被配置成框架的stream。在框架中，stream定义了图像的size及format。</li><li>每个request都需要携带target surface用于指定返回的图像是归属到哪个被configure的stream的。</li></ul></li><li>request处理流程（橙色箭头线条）<ul><li>CameraDevice对象通过createCaptureRequest()来创建request，每个reqeust都需要有surface和settings（settings就是metadata，request包含的所有配置信息都是放在metadata中的）。</li><li>使用session的capture()、captureBurst()、setStreamingRequest()、setStreamingBurst()等api可以将request发送到框架。</li><li>预览的request，通过setStreamingRequest()、setStreamingBurst()发送，仅调用一次。将request set到repeating request list里面。只要pending request queue里面没有request，就将repeating list里面的request copy到pending queue里面。</li><li>拍照的request，通过capture()、captureBurst()发送，每次需要拍照都会调用。每次触发，都会直接将request入到pending request queue里面，所以拍照的request比预览的request的优先级更高。</li><li>in-progress queue代表当前正在处理的request的queue，每处理完一个，都会从pending queue里面拿出来一个新的request放到这里。</li></ul></li><li>数据返回流程（紫色箭头线条）<ul><li>硬件层面返回的数据会放到result里面返回，会通过session的capture callback回调响应。</li></ul></li></ul><h1 id="request在HAL的处理方式"><a href="#request在HAL的处理方式" class="headerlink" title="request在HAL的处理方式"></a>request在HAL的处理方式</h1><ol><li>framework发送异步的request到hal。</li><li>hal必须顺序处理request，对于每一个request都要返回timestamp（shutter，也就是帧的生成时间）、metadata、image buffers。</li><li>对于request引用的每一类steam，必须按FIFO的方式返回result。比如：对于预览的stream，result id 9必须要先于result id 10返回。但是拍照的stream，当前可以只返回到result id 7，因为拍照和预览用的stream不一样。</li><li>hal需要的信息都通过request携带的metadata接收，hal需要返回的信息都通过result携带的metadata返回。</li></ol><p>HAL处理request的整体流程如下图。<br><img src="/Android%E7%9B%B8%E6%9C%BA%E6%9E%B6%E6%9E%84/camera-hal-overview-16790768588878.png" alt="相机 HAL 概览"></p><ul><li>request处理流程（黑色箭头线条）<ul><li>framework异步地submit request到hal，hal依次处理，并返回result。</li><li>每个被submit到hal的request都必须携带stream。stream分为input stream和output stream：input stream对应的buffer是已有图像数据的buffer，hal对这些buffer进行reprocess；output stream对应的buffer是empty buffer，hal将生成的图像数据填充的这些buffer里面。</li></ul></li><li>input stream处理流程（图像的INPUT STREAM 1）<ul><li>request携带input stream及input buffer到hal。</li><li>hal进行reprocess，然后新的图像数据重新填充到buffer里面，返回到framework。</li></ul></li><li>output stream处理流程（图像的OUTPUT STREAM 1…N）<ul><li>request携带output stream及output buffer到hal。</li><li>hal经过一系列模块的的处理，将图像数据写到buffer中，返回到frameowork。</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Android相机软件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Android </tag>
            
            <tag> Camera </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
